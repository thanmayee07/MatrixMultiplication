{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNuRqkQH1IxXL9nrie3LxMV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thanmayee07/MatrixMultiplication/blob/main/gemm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fxJl7vHwfm2F",
        "outputId": "bc068409-4227-4f9f-ae89-5164f0aa998a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Mar  4 03:24:13 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1oeTkzpRFlrA",
        "outputId": "de512bca-87d6-41af-e396-9d304b874d9c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RpXqIBhkGBP_",
        "outputId": "637fe3db-eb2e-44aa-95d4-be2367bb85da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-q5xphtic\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-q5xphtic\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 326b0a57a80c6d0b4bad25ca7adf8138419ef1cb\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10741 sha256=1c43b610d84440f376c57bb0b3d20f87e2433fdb6f06eb98d5fd7c81c461a971\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-948gcwsq/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip show nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9RajyAEsHniy",
        "outputId": "ebdf2527-ea9f-4d28-b2bb-804608777a62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Name: nvcc4jupyter\n",
            "Version: 1.2.1\n",
            "Summary: Jupyter notebook plugin to run CUDA C/C++ code\n",
            "Home-page: \n",
            "Author: \n",
            "Author-email: Andrei Nechaev <lyfaradey@yahoo.com>, Cosmin Stefan Ciocan <ciocan.cosmin98@gmail.com>\n",
            "License: MIT License\n",
            "Location: /usr/local/lib/python3.10/dist-packages\n",
            "Requires: \n",
            "Required-by: \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T_54IB8IkA3",
        "outputId": "80571f90-eac2-4c5f-b81f-226a65a549de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmp7pm0ep2l\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "\n",
        "__global__ void hello(){\n",
        "    printf(\"Hello from block: %u, thread: %u\\n\", blockIdx.x, threadIdx.x);\n",
        "}\n",
        "\n",
        "int main(){\n",
        "    hello<<<2, 2>>>();\n",
        "    cudaDeviceSynchronize();\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVoPgoRCIl3n",
        "outputId": "5a8342fa-e9e3-4e31-ed02-46b9350475bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello from block: 0, thread: 0\n",
            "Hello from block: 0, thread: 1\n",
            "Hello from block: 1, thread: 0\n",
            "Hello from block: 1, thread: 1\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <iostream>\n",
        "int main() {\n",
        "    std::cout << \"Hello world\\n\";\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awzzEL5YIs59",
        "outputId": "7166e411-529e-4c91-b4ae-d4aa30820225"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello world\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "\n",
        "// Print device properties\n",
        "void printDevProp(cudaDeviceProp devProp)\n",
        "{\n",
        "    printf(\"Major revision number:         %d\\n\",  devProp.major);\n",
        "    printf(\"Minor revision number:         %d\\n\",  devProp.minor);\n",
        "    printf(\"Name:                          %s\\n\",  devProp.name);\n",
        "    printf(\"Total global memory:           %u\\n\",  devProp.totalGlobalMem);\n",
        "    printf(\"Total shared memory per block: %u\\n\",  devProp.sharedMemPerBlock);\n",
        "    printf(\"Total registers per block:     %d\\n\",  devProp.regsPerBlock);\n",
        "    printf(\"Warp size:                     %d\\n\",  devProp.warpSize);\n",
        "    printf(\"Maximum memory pitch:          %u\\n\",  devProp.memPitch);\n",
        "    printf(\"Maximum threads per block:     %d\\n\",  devProp.maxThreadsPerBlock);\n",
        "    for (int i = 0; i < 3; ++i)\n",
        "    printf(\"Maximum dimension %d of block:  %d\\n\", i, devProp.maxThreadsDim[i]);\n",
        "    for (int i = 0; i < 3; ++i)\n",
        "    printf(\"Maximum dimension %d of grid:   %d\\n\", i, devProp.maxGridSize[i]);\n",
        "    printf(\"Clock rate:                    %d\\n\",  devProp.clockRate);\n",
        "    printf(\"Total constant memory:         %u\\n\",  devProp.totalConstMem);\n",
        "    printf(\"Texture alignment:             %u\\n\",  devProp.textureAlignment);\n",
        "    printf(\"Concurrent copy and execution: %s\\n\",  (devProp.deviceOverlap ? \"Yes\" : \"No\"));\n",
        "    printf(\"Number of multiprocessors:     %d\\n\",  devProp.multiProcessorCount);\n",
        "    printf(\"Kernel execution timeout:      %s\\n\",  (devProp.kernelExecTimeoutEnabled ? \"Yes\" : \"No\"));\n",
        "//           printf(\"CUDA Cores= %d\\n\" , __ConvertSMVer2Cores(devProp.major, deviceProp.minor) *        devProp.multiProcessorCount);\n",
        "    return;\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    // Number of CUDA devices\n",
        "    int devCount;\n",
        "    cudaGetDeviceCount(&devCount);\n",
        "    printf(\"CUDA Device Query...\\n\");\n",
        "    printf(\"There are %d CUDA devices.\\n\", devCount);\n",
        "\n",
        "    // Iterate through devices\n",
        "    for (int i = 0; i < devCount; ++i)\n",
        "    {\n",
        "        // Get device properties\n",
        "        printf(\"\\nCUDA Device #%d\\n\", i);\n",
        "        cudaDeviceProp devProp;\n",
        "        cudaGetDeviceProperties(&devProp, i);\n",
        "        printDevProp(devProp);\n",
        "    }\n",
        "\n",
        "    printf(\"\\nPress any key to exit...\");\n",
        "    char c;\n",
        "    scanf(\"%c\", &c);\n",
        "\n",
        "    return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nJ3sLrb-kHnH",
        "outputId": "a5f7b142-6e78-4c92-890e-9b6e75c09483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA Device Query...\n",
            "There are 1 CUDA devices.\n",
            "\n",
            "CUDA Device #0\n",
            "Major revision number:         7\n",
            "Minor revision number:         5\n",
            "Name:                          Tesla T4\n",
            "Total global memory:           2950758400\n",
            "Total shared memory per block: 49152\n",
            "Total registers per block:     65536\n",
            "Warp size:                     32\n",
            "Maximum memory pitch:          2147483647\n",
            "Maximum threads per block:     1024\n",
            "Maximum dimension 0 of block:  1024\n",
            "Maximum dimension 1 of block:  1024\n",
            "Maximum dimension 2 of block:  64\n",
            "Maximum dimension 0 of grid:   2147483647\n",
            "Maximum dimension 1 of grid:   65535\n",
            "Maximum dimension 2 of grid:   65535\n",
            "Clock rate:                    1590000\n",
            "Total constant memory:         65536\n",
            "Texture alignment:             512\n",
            "Concurrent copy and execution: Yes\n",
            "Number of multiprocessors:     40\n",
            "Kernel execution timeout:      No\n",
            "\n",
            "Press any key to exit...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <time.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "#define N 128\n",
        "#define BLOCK_SIZE 32\n",
        "\n",
        "// Tiled matrix multiplication kernel using shared memory\n",
        "__global__ void matrixMulTiled(float *a, float *b, float *c) {\n",
        "    // Define shared memory for tiles of matrix 'a' and 'b'\n",
        "    __shared__ float tile_a[BLOCK_SIZE][BLOCK_SIZE];\n",
        "    __shared__ float tile_b[BLOCK_SIZE][BLOCK_SIZE];\n",
        "\n",
        "    // Calculate row and column indices\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    // Accumulator for the dot product\n",
        "    float sum = 0.0f;\n",
        "\n",
        "    // Iterate over tiles\n",
        "    for (int t = 0; t < N / BLOCK_SIZE; ++t) {\n",
        "        // Load tiles of matrix 'a' and 'b' into shared memory\n",
        "        tile_a[threadIdx.y][threadIdx.x] = a[row * N + t * BLOCK_SIZE + threadIdx.x];\n",
        "        tile_b[threadIdx.y][threadIdx.x] = b[(t * BLOCK_SIZE + threadIdx.y) * N + col];\n",
        "\n",
        "        // Synchronize threads to ensure all tiles are loaded\n",
        "        __syncthreads();\n",
        "\n",
        "        // Compute dot product of tiles\n",
        "        for (int k = 0; k < BLOCK_SIZE; ++k) {\n",
        "            sum += tile_a[threadIdx.y][k] * tile_b[k][threadIdx.x];\n",
        "        }\n",
        "\n",
        "        // Synchronize threads before loading next tiles\n",
        "        __syncthreads();\n",
        "    }\n",
        "\n",
        "    // Write the result to global memory\n",
        "    if (row < N && col < N) {\n",
        "        c[row * N + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    float *a, *b, *c;\n",
        "    float *d_a, *d_b, *d_c;\n",
        "    int size = N * N * sizeof(float);\n",
        "\n",
        "    // Allocate host memory\n",
        "    a = (float *)malloc(size);\n",
        "    b = (float *)malloc(size);\n",
        "    c = (float *)malloc(size);\n",
        "\n",
        "    // Initialize host matrices a and b\n",
        "    for(int i = 0; i < N; ++i) {\n",
        "        for(int j = 0; j < N; ++j) {\n",
        "            a[i * N + j] = i + j;\n",
        "            b[i * N + j] = i - j;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Allocate device memory\n",
        "    cudaMalloc((void **)&d_a, size);\n",
        "    cudaMalloc((void **)&d_b, size);\n",
        "    cudaMalloc((void **)&d_c, size);\n",
        "\n",
        "    // Copy host matrices to device\n",
        "    cudaMemcpy(d_a, a, size, cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, size, cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Set grid and block dimensions\n",
        "    dim3 threadsPerBlock(BLOCK_SIZE, BLOCK_SIZE);\n",
        "    dim3 numBlocks((N + BLOCK_SIZE - 1) / BLOCK_SIZE, (N + BLOCK_SIZE - 1) / BLOCK_SIZE);\n",
        "\n",
        "    cudaEvent_t start, stop;\n",
        "    cudaEventCreate(&start);\n",
        "    cudaEventCreate(&stop);\n",
        "    cudaEventRecord(start);\n",
        "\n",
        "    // Launch kernel\n",
        "    matrixMulTiled<<<numBlocks, threadsPerBlock>>>(d_a, d_b, d_c);\n",
        "\n",
        "    cudaEventRecord(stop);\n",
        "    cudaEventSynchronize(stop);\n",
        "\n",
        "    float milliseconds = 0;\n",
        "    cudaEventElapsedTime(&milliseconds, start, stop);\n",
        "\n",
        "    // Calculate the total number of floating-point operations\n",
        "    long long total_flops = 2 * (long long)N * (long long)N * (long long)N;\n",
        "\n",
        "    // Convert time to seconds\n",
        "    double seconds = milliseconds / 1000.0;\n",
        "\n",
        "    // Calculate GFLOPS\n",
        "    double gflops = total_flops / (seconds * 1e9); // Convert time to seconds and GFLOPS to 1e9 scale\n",
        "    double throughput = total_flops / seconds; // Throughput in operations per second\n",
        "\n",
        "\n",
        "    printf(\"Time taken: %f milliseconds\\n\", milliseconds);\n",
        "    printf(\"GFLOPS: %f\\n\", gflops);\n",
        "    printf(\"Throughput: %f OPS\\n\", throughput);\n",
        "\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(c, d_c, size, cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "epkK1nkxuBKZ",
        "outputId": "2d9942e8-16ff-40d3-d4b8-89badd40c28f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken: 270.421356 milliseconds\n",
            "GFLOPS: 508.240013\n",
            "Throughput: 508240012559.349854 OPS\n",
            "\n"
          ]
        }
      ]
    }
  ]
}